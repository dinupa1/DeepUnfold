{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0889dcba-c05e-4572-9340-2d4425bb675b",
   "metadata": {},
   "source": [
    "# Generative Algorithm for Multidimensional Unfolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28daf005-8210-4894-a4f3-c0f728e92027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import hist\n",
    "from hist import Hist\n",
    "\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e94a87-891b-4d39-a537-01b6d7a4701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = uproot.open(\"data/DY_DUMP_4pi_GMC_Jan08_LD2.root:result_mc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64f435b9-e290-4a99-bf8f-701992e33b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5970312, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tree.arrays([\"weight\", \"mass\", \"pT\", \"xF\", \"phi\", \"costh\", \"true_mass\", \"true_pT\", \"true_xF\", \"true_phi\", \"true_costh\"],\n",
    "                   \"(fpga1==1) & (true_mass > 4.) & (true_mass < 8.0)\",\n",
    "                  library=\"pd\")\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92907bbc-a0e4-4bcb-be2d-afd74b04982e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5970092, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdfe2f08-4f2b-4139-98ba-d9961646491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data = data[[\"weight\", \"true_mass\", \"true_pT\", \"true_xF\", \"true_phi\", \"true_costh\"]].to_numpy()\n",
    "reco_data = data[[\"weight\", \"mass\", \"pT\", \"xF\", \"phi\", \"costh\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7acee0f-860e-4a71-948b-f0ab792f90cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reco_train, reco_test, true_train, true_test = train_test_split(reco_data, true_data, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a86f98d7-f920-4cd9-a752-b7314706ab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** train data : gen = (4179064, 6) & reco = (4179064, 6) ***\n",
      "*** test data : gen = (1791028, 6) & reco = (1791028, 6) ***\n"
     ]
    }
   ],
   "source": [
    "print(\"*** train data : gen = {} & reco = {} ***\".format(true_train.shape, reco_train.shape))\n",
    "print(\"*** test data : gen = {} & reco = {} ***\".format(true_test.shape, reco_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa4fc84-3638-4d5a-811a-4b4304fb3f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 500000\n",
    "\n",
    "dataset = TensorDataset(torch.Tensor(reco_train[:, 1:]), torch.Tensor(true_train[:, 1:]))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882489a7-7bce-44cc-99da-9e0a2cb22b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, dim: int=5):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(dim , 500),\n",
    "            nn.BatchNorm1d(500),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(500, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.fc3 = nn.Linear(100, dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aab64fe-b8f5-42d9-8a04-e0497ac0f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, dim: int=5):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(dim, 1000),\n",
    "            nn.BatchNorm1d(1000),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.BatchNorm1d(500),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(500, 200),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.fc4 = nn.Sequential(\n",
    "            nn.Linear(200, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80a961b0-1324-4404-8c9a-7e8aff3788ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = Discriminator()\n",
    "netG = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a54d89a4-b74d-41a1-a562-7a2e2f773ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterionD = nn.BCELoss()\n",
    "criterionG = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95e21780-5891-474d-ab2b-79acd39ca8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=0.001)\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4d966-67df-4728-9ec0-a587b020a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "lossesD, lossesG = [], []\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for rec_data, gen_data in dataloader:\n",
    "        \n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        netD.zero_grad()\n",
    "        \n",
    "        b_size = gen_data.shape[0]\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float)\n",
    "        \n",
    "        output = netD(gen_data).view(-1)\n",
    "        errD_real = criterionD(output, label)\n",
    "        errD_real.backward()\n",
    "        \n",
    "        fake = netG(rec_data)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        errD_fake = criterionD(output, label)\n",
    "        errD_fake.backward()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        \n",
    "        netG.zero_grad()\n",
    "        \n",
    "        output = netG(rec_data)\n",
    "        errG = criterionG(output, gen_data)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        lossesD.append(errD.item())\n",
    "        lossesG.append(errG.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4c4e21-5c68-4085-8f77-0aacf8097af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossesD, label=\"LD\")\n",
    "plt.plot(lossesG, label=\"LG\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c652a4b-9bb0-4719-8984-3128dc386f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
